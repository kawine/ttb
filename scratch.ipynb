{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recovering the train and test streams\n",
    "train_stream = b.train_stream\n",
    "test_stream = b.test_stream\n",
    "\n",
    "# iterating over the train stream\n",
    "for experience in train_stream:\n",
    "  print(\"Start of task \", experience.task_label)\n",
    "  print('Classes in this task:', experience.classes_in_this_experience)\n",
    "\n",
    "  # The current Pytorch training set can be easily recovered through the\n",
    "  # experience\n",
    "  current_training_set = experience.dataset\n",
    "  # ...as well as the task_label\n",
    "  print('Task {}'.format(experience.task_label))\n",
    "  print('This task contains', len(current_training_set), 'training examples')\n",
    "  \n",
    "  print(\"Train\")\n",
    "  for idx, elem in enumerate(current_training_set):\n",
    "    print(elem)\n",
    "    if idx > 10:\n",
    "      break\n",
    "\n",
    "  # we can recover the corresponding test experience in the test stream\n",
    "  current_test_set = test_stream[experience.current_experience].dataset\n",
    "  print('This task contains', len(current_test_set), 'test examples')\n",
    "  \n",
    "  print(\"Test\")\n",
    "  for idx, elem in enumerate(current_test_set):\n",
    "    print(elem)\n",
    "    if idx > 10:\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n",
      "Iteration 10: 10.868417329812118\n",
      "Iteration 20: 10.862375475625317\n",
      "Iteration 30: 10.843499722441528\n",
      "Iteration 40: 10.855939225985555\n"
     ]
    }
   ],
   "source": [
    "from ttb import STREAMSDataset\n",
    "\n",
    "ds = STREAMSDataset(\"mnist\", T=50, inference_window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]]\n",
      "<torch.utils.data.dataset.Subset object at 0x28cdc16d0>\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/shreyashankar/Documents/projects/ttb/scratch.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/shreyashankar/Documents/projects/ttb/scratch.ipynb#ch0000013?line=0'>1</a>\u001b[0m ds\u001b[39m.\u001b[39;49mget_benchmark()\n",
      "File \u001b[0;32m~/Documents/projects/ttb/ttb/streamsdataset.py:85\u001b[0m, in \u001b[0;36mSTREAMSDataset.get_benchmark\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='file:///~/Documents/projects/ttb/ttb/streamsdataset.py?line=82'>83</a>\u001b[0m \u001b[39mprint\u001b[39m(exp_assignment)\n\u001b[1;32m     <a href='file:///~/Documents/projects/ttb/ttb/streamsdataset.py?line=83'>84</a>\u001b[0m \u001b[39mprint\u001b[39m(train_dataset)\n\u001b[0;32m---> <a href='file:///~/Documents/projects/ttb/ttb/streamsdataset.py?line=84'>85</a>\u001b[0m benchmark \u001b[39m=\u001b[39m ni_benchmark(\n\u001b[1;32m     <a href='file:///~/Documents/projects/ttb/ttb/streamsdataset.py?line=85'>86</a>\u001b[0m     train_dataset\u001b[39m=\u001b[39;49mtrain_dataset,\n\u001b[1;32m     <a href='file:///~/Documents/projects/ttb/ttb/streamsdataset.py?line=86'>87</a>\u001b[0m     test_dataset\u001b[39m=\u001b[39;49mtest_dataset,\n\u001b[1;32m     <a href='file:///~/Documents/projects/ttb/ttb/streamsdataset.py?line=87'>88</a>\u001b[0m     n_experiences\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='file:///~/Documents/projects/ttb/ttb/streamsdataset.py?line=88'>89</a>\u001b[0m     seed\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseed,\n\u001b[1;32m     <a href='file:///~/Documents/projects/ttb/ttb/streamsdataset.py?line=89'>90</a>\u001b[0m     fixed_exp_assignment\u001b[39m=\u001b[39;49mexp_assignment,\n\u001b[1;32m     <a href='file:///~/Documents/projects/ttb/ttb/streamsdataset.py?line=90'>91</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///~/Documents/projects/ttb/ttb/streamsdataset.py?line=91'>92</a>\u001b[0m \u001b[39mreturn\u001b[39;00m benchmark\n",
      "File \u001b[0;32m~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/generators/benchmark_generators.py:321\u001b[0m, in \u001b[0;36mni_benchmark\u001b[0;34m(train_dataset, test_dataset, n_experiences, task_labels, shuffle, seed, balance_experiences, min_class_patterns_in_exp, fixed_exp_assignment, train_transform, eval_transform, reproducibility_data)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/generators/benchmark_generators.py?line=308'>309</a>\u001b[0m seq_train_dataset \u001b[39m=\u001b[39m AvalancheDataset(\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/generators/benchmark_generators.py?line=309'>310</a>\u001b[0m     seq_train_dataset,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/generators/benchmark_generators.py?line=310'>311</a>\u001b[0m     transform_groups\u001b[39m=\u001b[39mtransform_groups,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/generators/benchmark_generators.py?line=311'>312</a>\u001b[0m     initial_transform_group\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/generators/benchmark_generators.py?line=312'>313</a>\u001b[0m     dataset_type\u001b[39m=\u001b[39mAvalancheDatasetType\u001b[39m.\u001b[39mCLASSIFICATION)\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/generators/benchmark_generators.py?line=314'>315</a>\u001b[0m seq_test_dataset \u001b[39m=\u001b[39m AvalancheDataset(\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/generators/benchmark_generators.py?line=315'>316</a>\u001b[0m     seq_test_dataset,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/generators/benchmark_generators.py?line=316'>317</a>\u001b[0m     transform_groups\u001b[39m=\u001b[39mtransform_groups,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/generators/benchmark_generators.py?line=317'>318</a>\u001b[0m     initial_transform_group\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39meval\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/generators/benchmark_generators.py?line=318'>319</a>\u001b[0m     dataset_type\u001b[39m=\u001b[39mAvalancheDatasetType\u001b[39m.\u001b[39mCLASSIFICATION)\n\u001b[0;32m--> <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/generators/benchmark_generators.py?line=320'>321</a>\u001b[0m \u001b[39mreturn\u001b[39;00m NIScenario(\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/generators/benchmark_generators.py?line=321'>322</a>\u001b[0m     seq_train_dataset, seq_test_dataset,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/generators/benchmark_generators.py?line=322'>323</a>\u001b[0m     n_experiences,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/generators/benchmark_generators.py?line=323'>324</a>\u001b[0m     task_labels,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/generators/benchmark_generators.py?line=324'>325</a>\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle, seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/generators/benchmark_generators.py?line=325'>326</a>\u001b[0m     balance_experiences\u001b[39m=\u001b[39;49mbalance_experiences,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/generators/benchmark_generators.py?line=326'>327</a>\u001b[0m     min_class_patterns_in_exp\u001b[39m=\u001b[39;49mmin_class_patterns_in_exp,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/generators/benchmark_generators.py?line=327'>328</a>\u001b[0m     fixed_exp_assignment\u001b[39m=\u001b[39;49mfixed_exp_assignment,\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/generators/benchmark_generators.py?line=328'>329</a>\u001b[0m     reproducibility_data\u001b[39m=\u001b[39;49mreproducibility_data)\n",
      "File \u001b[0;32m~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/scenarios/new_instances/ni_scenario.py:154\u001b[0m, in \u001b[0;36mNIScenario.__init__\u001b[0;34m(self, train_dataset, test_dataset, n_experiences, task_labels, shuffle, seed, balance_experiences, min_class_patterns_in_exp, fixed_exp_assignment, reproducibility_data)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/scenarios/new_instances/ni_scenario.py?line=151'>152</a>\u001b[0m     class_id \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(unique_targets[unique_idx])\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/scenarios/new_instances/ni_scenario.py?line=152'>153</a>\u001b[0m     class_count \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(unique_count[unique_idx])\n\u001b[0;32m--> <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/scenarios/new_instances/ni_scenario.py?line=153'>154</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_patterns_per_class[class_id] \u001b[39m=\u001b[39m class_count\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/scenarios/new_instances/ni_scenario.py?line=155'>156</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_patterns_per_experience: List[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/scenarios/new_instances/ni_scenario.py?line=156'>157</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/scenarios/new_instances/ni_scenario.py?line=157'>158</a>\u001b[0m \u001b[39mThe number of patterns in each experience.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniforge3/envs/ttb/lib/python3.9/site-packages/avalanche/benchmarks/scenarios/new_instances/ni_scenario.py?line=158'>159</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "ds.get_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = ds.get_data(include_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = ni_benchmark(\n",
    "            train_dataset=train_dataset,\n",
    "            test_dataset=test_dataset,\n",
    "            n_experiences=1,\n",
    "            seed=1,\n",
    "            # fixed_exp_assignment=exp_assignment,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "125e6e438f6bf169001eca1db6f9b76bb8629196a71bc9c758d46cb6243b56f5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
